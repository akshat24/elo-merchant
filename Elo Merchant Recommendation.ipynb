{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a team project. The team members include : Harsh Patel, Deep Talati, Akshat Vaidya, Xingyi Wang and Lei Xia.\n",
    "<br>\n",
    "Topic: Prediction of Customer Loyalty Score for Elo (Kaggle Competition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "\n",
    "<a href='#section1'>1. Importing needed libraries</a>\n",
    "<br>\n",
    "<a href='#section2'>2. Data Visualization and EDA</a>\n",
    "<br>\n",
    "<a href='#section3'>3. Data Pre-Processing</a>\n",
    "<br>\n",
    "<a href='#section5'>5. Boosting</a>\n",
    "<br>\n",
    "<a href='#section6'>6. Random Forests</a>\n",
    "<br>\n",
    "<a href='#section7'>7. References </a>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path variable stores the path of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'original/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduce_mem_usage functions is used to speed up the reading of files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(pd.read_csv(path+'train.csv'))\n",
    "test = reduce_mem_usage(pd.read_csv(path+'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['first_active_month'] = pd.to_datetime(train['first_active_month'])\n",
    "test['first_active_month'] = pd.to_datetime(test['first_active_month'])\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted the first_active_month into a date from object datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visulization and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4,3])\n",
    "plt.bar([0, 1], [train.shape[0], test.shape[0]], edgecolor=[0.2]*3, color=(1,0,0,0.5))\n",
    "plt.xticks([0,1], ['train rows', 'test rows'], fontsize=13)\n",
    "plt.title('Number of rows in train.csv and test.csv', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.suptitle('Feature distributions in train.csv and test.csv', fontsize=20, y=1.1)\n",
    "for num, col in enumerate(['feature_1', 'feature_2', 'feature_3', 'target']):\n",
    "    plt.subplot(2, 4, num+1)\n",
    "    if col is not 'target':\n",
    "        v_c = train[col].value_counts() / train.shape[0]\n",
    "        plt.bar(v_c.index, v_c, label=('train'), align='edge', width=-0.3, edgecolor=[0.2]*3)\n",
    "        v_c = test[col].value_counts() / test.shape[0]\n",
    "        plt.bar(v_c.index, v_c, label=('test'), align='edge', width=0.3, edgecolor=[0.2]*3)\n",
    "        plt.title(col)\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.hist(train[col], bins = 100)\n",
    "        plt.title(col)\n",
    "    plt.tight_layout()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.abs(train.corr())\n",
    "np.fill_diagonal(corrs.values, 0)\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.imshow(corrs, cmap='plasma', vmin=0, vmax=1)\n",
    "plt.colorbar(shrink=0.7)\n",
    "plt.xticks(range(corrs.shape[0]), list(corrs.columns))\n",
    "plt.yticks(range(corrs.shape[0]), list(corrs.columns))\n",
    "plt.title('Correlations between target and user\\'s features', fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train['first_active_month'].dt.month\n",
    "test['month'] = test['first_active_month'].dt.month\n",
    "\n",
    "train['year'] = train['first_active_month'].dt.year\n",
    "test['year'] = test['first_active_month'].dt.year\n",
    "\n",
    "train['time_diff'] = (datetime.date(2018, 2, 1) - train['first_active_month'].dt.date).dt.days\n",
    "test['time_diff'] = (datetime.date(2018, 2, 1) - test['first_active_month'].dt.date).dt.days\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['feature_1', 'feature_2'])\n",
    "test = pd.get_dummies(test, columns=['feature_1', 'feature_2'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = reduce_mem_usage(pd.read_csv(path+'historical_transactions.csv'))\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['authorized_flag'] = hist['authorized_flag'].map({'Y':1, 'N':0})\n",
    "hist['category_1'] = hist['category_1'].map({'Y':1, 'N':0})\n",
    "hist = pd.get_dummies(hist, columns=['category_2', 'category_3'])\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new_aggregate_cols function is used for creating the aggregated fields. It groups transactions on card_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_aggregate_cols(df, prefix):\n",
    "    agg_func = {\n",
    "        'authorized_flag': ['sum','mean'],\n",
    "        'category_1': ['sum','mean'],\n",
    "        'category_2_1.0': ['sum','mean'],\n",
    "        'category_2_2.0': ['sum','mean'],\n",
    "        'category_2_3.0': ['sum','mean'],\n",
    "        'category_2_4.0': ['sum','mean'],\n",
    "        'category_2_5.0': ['sum','mean'],\n",
    "        'category_3_A': ['sum','mean'],\n",
    "        'category_3_B': ['sum','mean'],\n",
    "        'category_3_C': ['sum','mean'],\n",
    "        'merchant_id': ['nunique','count'],\n",
    "        'purchase_amount': ['sum','mean','min','max','std'],\n",
    "        'installments': ['sum','mean','min','max','std'],\n",
    "        'month_lag': ['sum','mean','min','max','std']\n",
    "        \n",
    "    }\n",
    "    agg_df = df.groupby(['card_id']).agg(agg_func)\n",
    "    agg_df.columns = [prefix + '_'.join(col).strip() for col in agg_df.columns.values]\n",
    "    agg_df.reset_index(inplace=True)\n",
    "    \n",
    "    df1 = (df.groupby('card_id').size().reset_index(name='{}transactions_count'.format(prefix)))\n",
    "    \n",
    "    agg_df = pd.merge(df1, agg_df, on='card_id', how='left')\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "history_trans = new_aggregate_cols(hist, prefix='hist_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gc is the garbage collector. It is invoked to clean up the memory. The historical transactions is large file and keeping it in memory causes performance issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, history_trans, on='card_id', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test, history_trans, on='card_id', how='left')\n",
    "del history_trans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merch_trans = reduce_mem_usage(pd.read_csv(path+'new_merchant_transactions.csv'))\n",
    "new_merch_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and test are merged with the aggregated features of historical transactions. This is basically a join operation. It is a left join performed on card_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merch_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merch_trans = pd.get_dummies(new_merch_trans, columns=['category_2','category_3'])\n",
    "new_merch_trans['authorized_flag'] = new_merch_trans['authorized_flag'].map({'Y':1, 'N':0})\n",
    "new_merch_trans['category_1'] = new_merch_trans['category_1'].map({'Y':1, 'N':0})\n",
    "new_merch_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_new = new_aggregate_cols(new_merch_trans, 'new_merch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_merch_trans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, merch_new, on='card_id', how='left')\n",
    "test = pd.merge(test, merch_new, on='card_id', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merch_new\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset and target score labels are created here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['target']\n",
    "drop_cols = ['card_id','first_active_month','target']\n",
    "use_cols = [c for c in train.columns if c not in drop_cols]\n",
    "features = list(train[use_cols].columns)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#section5.1'>Baseline Model</a><br>\n",
    "<a href='#section5.2'>Identifying top features</a><br>\n",
    "<a href='#section5.3'>Tuning of Hyperparameters</a><br>\n",
    "<a href='#section5.4'>Best Model</a><br>\n",
    "<a href='#section5.5'>Feature importance</a><br>\n",
    "<a href='#section5.6'>SHAP Feature Importance</a><br>\n",
    "<a href='#section5.7'>Boosting with top 10 features (Tuned Model)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, metrics, preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'num_leaves':50,\n",
    "    'min_data_in_leaf':30,\n",
    "    'objective':'regression',\n",
    "    'max_depth':-1,\n",
    "    'learning_rate':0.005,\n",
    "    'boosting':'gbdt',\n",
    "    'feature_fraction':0.9,\n",
    "    'bagging_freq':1,\n",
    "    'bagging_fraction':0.9,\n",
    "    'bagging_seed':46,\n",
    "    'metric':'rmse',\n",
    "    'lambda_l1':0.1,\n",
    "    'verbosity':-1\n",
    "}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter values are randomly chosen here! <br>\n",
    "K-Fold cross validation is performed with K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print('-')\n",
    "    print('Fold {}'.format(fold_ + 1))\n",
    "    train_data = lgb.Dataset(train.iloc[train_idx][features], label=target.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    \n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, train_data, num_round, valid_sets=[train_data, val_data], verbose_eval=100, \n",
    "                    early_stopping_rounds=100)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE Score for Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "val_score = np.sqrt(mean_squared_error(target,oof))\n",
    "val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 50 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,11))\n",
    "lgb.plot_importance(clf, max_num_features=50, height=0.5, ax=ax, title='Feature Importance', xlabel='Importance',\n",
    "                   ylabel='Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(clf.feature_importance(), features)), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the top 30 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score, f_names = zip(*f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top30 = list(f_names[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting with top 30 features (untuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'num_leaves':50,\n",
    "    'min_data_in_leaf':30,\n",
    "    'objective':'regression',\n",
    "    'max_depth':-1,\n",
    "    'learning_rate':0.005,\n",
    "    'boosting':'gbdt',\n",
    "    'feature_fraction':0.9,\n",
    "    'bagging_freq':1,\n",
    "    'bagging_fraction':0.9,\n",
    "    'bagging_seed':46,\n",
    "    'metric':'rmse',\n",
    "    'lambda_l1':0.1,\n",
    "    'verbosity':-1\n",
    "}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print('-')\n",
    "    print('Fold {}'.format(fold_ + 1))\n",
    "    train_data = lgb.Dataset(train.iloc[train_idx][top30], label=target.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][top30], label=target.iloc[val_idx])\n",
    "    \n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, train_data, num_round, valid_sets=[train_data, val_data], verbose_eval=100, \n",
    "                    early_stopping_rounds=100)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][top30], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test[top30], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = np.sqrt(mean_squared_error(target,oof))\n",
    "val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,11))\n",
    "lgb.plot_importance(clf, max_num_features=50, height=0.5, ax=ax, title='Feature Importance', xlabel='Importance',\n",
    "                   ylabel='Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyperparameters for the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a <strong><u>long time to run (~3 hours)</u></strong> but identifies the best set of hyperparameters value for the model. It uses a Bayesian Optimization framework and is particularly well suited when cost of exploration is high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_CV(\n",
    "          max_depth,\n",
    "          num_leaves,\n",
    "          min_data_in_leaf,\n",
    "          feature_fraction,\n",
    "          bagging_fraction,\n",
    "          lambda_l1\n",
    "         ):\n",
    "    \n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(train.shape[0])\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features],\n",
    "                               label=target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features],\n",
    "                               label=target.iloc[val_idx])\n",
    "    \n",
    "        param = {\n",
    "            'num_leaves': int(num_leaves),\n",
    "            'min_data_in_leaf': int(min_data_in_leaf), \n",
    "            'objective':'regression',\n",
    "            'max_depth': int(max_depth),\n",
    "            'learning_rate': 0.01,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": feature_fraction,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"bagging_fraction\": bagging_fraction ,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"metric\": 'rmse',\n",
    "            \"lambda_l1\": lambda_l1,\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "    \n",
    "        clf = lgb.train(param,\n",
    "                        trn_data,\n",
    "                        10000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds = 200)\n",
    "        \n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features],\n",
    "                                   num_iteration=clf.best_iteration)\n",
    "        \n",
    "        del clf, trn_idx, val_idx\n",
    "        gc.collect()\n",
    "        \n",
    "    return -mean_squared_error(oof, target)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_CV, {\n",
    "    'max_depth': (4, 10),\n",
    "    'num_leaves': (5, 130),\n",
    "    'min_data_in_leaf': (10, 150),\n",
    "    'feature_fraction': (0.7, 1.0),\n",
    "    'bagging_fraction': (0.7, 1.0),\n",
    "    'lambda_l1': (0, 6)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('<','-'*80,'>')\n",
    "LGB_BO.maximize(init_points=2, n_iter=20, acq='ei', xi=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {\n",
    "    'num_leaves':111,\n",
    "    'min_data_in_leaf':149,\n",
    "    'objective':'regression',\n",
    "    'max_depth':9,\n",
    "    'learning_rate':0.005,\n",
    "    'boosting':'gbdt',\n",
    "    'feature_fraction':0.7522,\n",
    "    'bagging_freq':1,\n",
    "    'bagging_fraction':0.7083,\n",
    "    'bagging_seed':11,\n",
    "    'metric':'rmse',\n",
    "    'lambda_l1':0.2634,\n",
    "    'random_state':133,\n",
    "    'verbosity':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "feature_imp = pd.DataFrame()\n",
    "\n",
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print('<------------------------------------------------------------->')\n",
    "    print('Fold {}'.format(fold_ + 1))\n",
    "    train_data = lgb.Dataset(train.iloc[train_idx][features], target.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], target.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    bclf = lgb.train(best_param, train_data, num_round, valid_sets=[train_data, val_data], verbose_eval=100,\n",
    "                   early_stopping_rounds=200)\n",
    "    oof[val_idx] = bclf.predict(train.iloc[val_idx][features], num_iteration=bclf.best_iteration)\n",
    "    \n",
    "    fold_imp = pd.DataFrame()\n",
    "    fold_imp['feature'] = features\n",
    "    fold_imp['importance'] = bclf.feature_importance()\n",
    "    fold_imp['fold'] = fold_ + 1\n",
    "    feature_imp = pd.concat([feature_imp, fold_imp], axis=0, ignore_index=True)\n",
    "    \n",
    "    predictions+= bclf.predict(test[features], num_iteration=bclf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV Score ', np.sqrt(mean_squared_error(target, oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 features by Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,11))\n",
    "lgb.plot_importance(bclf, max_num_features=30, ax=ax, height=0.5, xlabel='Importance',\n",
    "                   ylabel='Feature', title='Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 features by Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,11))\n",
    "lgb.plot_importance(bclf, max_num_features=30, ax=ax, height=0.5, xlabel='Importance',\n",
    "                   ylabel='Feature', title='Feature Importance', importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance by SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing SHAP values from the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(bclf).shap_values(train.iloc[val_idx][features])\n",
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_importances = np.abs(shap_values).mean(0)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, train.iloc[val_idx][features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('time_diff', shap_values, train.iloc[val_idx][features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('new_merch_purchase_amount_max', shap_values, train.iloc[val_idx][features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting with Top 10 features (Tuned Model)\n",
    "\n",
    "This is the model we recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = feature_imp.groupby(['feature']).mean()[['importance']].sort_values(by='importance', ascending=False)\n",
    "top10 = top10.reset_index()\n",
    "top10f = list(top10['feature'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print('<------------------------------------------------------------->')\n",
    "    print('Fold {}'.format(fold_ + 1))\n",
    "    train_data = lgb.Dataset(train.iloc[train_idx][top10f], target.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][top10f], target.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(best_param, train_data, num_round, valid_sets=[train_data, val_data], verbose_eval=100,\n",
    "                   early_stopping_rounds=200)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][top10f], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions+= clf.predict(test[top10f], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV Score ', np.sqrt(mean_squared_error(target, oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#section6.1'>Untuned Random Forest with all features</a><br>\n",
    "<a href='#section6.2'>Hyperparameter Tuning for Random Forest</a><br>\n",
    "<a href='#section6.3'>Tuned Random Forest with all features</a><br>\n",
    "<a href='#section6.4'>Feature Importance</a><br>\n",
    "<a href='#section6.5'>Tuned Random Forest with top 10 features</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#section6.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untuned Random Forest with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'num_leaves':50,\n",
    "    'min_data_in_leaf':30,\n",
    "    'objective':'regression',\n",
    "    'max_depth':-1,\n",
    "    'learning_rate':0.005,\n",
    "    'boosting':'gbdt',\n",
    "    'feature_fraction':0.9,\n",
    "    'bagging_freq':1,\n",
    "    'bagging_fraction':0.9,\n",
    "    'bagging_seed':46,\n",
    "    'metric':'rmse',\n",
    "    'lambda_l1':0.1,\n",
    "    'verbosity':-1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print('<------------------------------------------------------------->')\n",
    "    print('Fold {}'.format(fold_ + 1))\n",
    "    train_data = lgb.Dataset(train.iloc[train_idx][features], target.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], target.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, train_data, num_round, valid_sets=[train_data, val_data], verbose_eval=100,\n",
    "                   early_stopping_rounds=200)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions+= clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV Score ', np.sqrt(mean_squared_error(target, oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a long time to run! The learning rate value can be increased for faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_CV(\n",
    "          max_depth,\n",
    "          num_leaves,\n",
    "          min_data_in_leaf,\n",
    "          feature_fraction,\n",
    "          lambda_l1\n",
    "         ):\n",
    "    \n",
    "    folds = KFold(n_splits=5, shuffle=False, random_state=15)\n",
    "    oof = np.zeros(len(train))\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features],\n",
    "                               label=target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features],\n",
    "                               label=target.iloc[val_idx])\n",
    "    \n",
    "        param = {\n",
    "            'num_leaves': int(num_leaves),\n",
    "            'min_data_in_leaf': int(min_data_in_leaf), \n",
    "            'objective':'regression',\n",
    "            'max_depth': int(max_depth),\n",
    "            'learning_rate': 0.01,\n",
    "            \"boosting\": \"rf\",\n",
    "            \"feature_fraction\": feature_fraction,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"bagging_fraction\": 0.76 ,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"metric\": 'rmse',\n",
    "            \"lambda_l1\": lambda_l1,\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "    \n",
    "        clf = lgb.train(param,\n",
    "                        trn_data,\n",
    "                        10000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds = 200)\n",
    "        \n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features],\n",
    "                                   num_iteration=clf.best_iteration)\n",
    "        \n",
    "        del clf, trn_idx, val_idx\n",
    "        gc.collect()\n",
    "        \n",
    "    return -mean_squared_error(oof, target)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_CV, {\n",
    "    'max_depth': (4, 10),\n",
    "    'num_leaves': (5, 130),\n",
    "    'min_data_in_leaf': (10, 150),\n",
    "    'feature_fraction': (0.7, 1.0),\n",
    "    'lambda_l1': (0, 1)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('<','-'*80,'>')\n",
    "LGB_BO.maximize(init_points=2, n_iter=10, acq='ei', xi=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section 6.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {\n",
    "    'num_leaves':130,\n",
    "    'min_data_in_leaf':117,\n",
    "    'objective':'regression',\n",
    "    'max_depth':10,\n",
    "    'learning_rate':0.005,\n",
    "    'boosting':'rf',\n",
    "    'feature_fraction':0.7522,\n",
    "    'bagging_freq':1,\n",
    "    'bagging_fraction':0.9132,\n",
    "    'bagging_seed':11,\n",
    "    'metric':'rmse',\n",
    "    'lambda_l1':4.925,\n",
    "    'random_state':133,\n",
    "    'verbosity':-1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print('<------------------------------------------------------------->')\n",
    "    print('Fold {}'.format(fold_ + 1))\n",
    "    train_data = lgb.Dataset(train.iloc[train_idx][features], target.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], target.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(best_param, train_data, num_round, valid_sets=[train_data, val_data], verbose_eval=100,\n",
    "                   early_stopping_rounds=200)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions+= clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = np.sqrt(mean_squared_error(target, oof))\n",
    "val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='section6.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 features by split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11,13))\n",
    "lgb.plot_importance(clf, max_num_features=30, ax=ax, height=0.5, xlabel='Importance', ylabel='Feature',\n",
    "                   title='Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 features by gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11,13))\n",
    "lgb.plot_importance(clf, max_num_features=30, ax=ax, height=0.5, xlabel='Importance', ylabel='Feature',\n",
    "                   title='Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Random Forests with top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = sorted(list(zip(clf.feature_importance(), clf.feature_name())), reverse=True)\n",
    "_, names = zip(*l1)\n",
    "top10rf = list(names[:10])\n",
    "top10rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print('<------------------------------------------------------------->')\n",
    "    print('Fold {}'.format(fold_ + 1))\n",
    "    train_data = lgb.Dataset(train.iloc[train_idx][top10rf], target.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][top10rf], target.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(best_param, train_data, num_round, valid_sets=[train_data, val_data], verbose_eval=100,\n",
    "                   early_stopping_rounds=200)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][top10rf], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions+= clf.predict(test[top10rf], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = np.sqrt(mean_squared_error(target, oof))\n",
    "val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Model\n",
    "1. https://www.kaggle.com/fabiendaniel/elo-world\n",
    "2. https://www.kaggle.com/peterhurford/you-re-going-to-want-more-categories-lb-3-737\n",
    "\n",
    "For SHAP\n",
    "3. http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions\n",
    "4. https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27\n",
    "5. https://meichenlu.com/2018-11-10-SHAP-explainable-machine-learning/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
